---
title: "Volatile organic compounds clustering/ordination"
output: 
  github_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
knitr::opts_chunk$set(echo = FALSE, message = FALSE, fig.width = 14, fig.height = 6)

```

```{r libraries}
library(tidyverse)
library(vegan)
library(plotly)
library(corrplot)
library(ggpubr)
library(ggmosaic)
```

The clean RDS data file should be available locally after you run the `master_cleanup.R` file.This will take the master csv data file and output the RDS we use here. The data we will be using has no duplicates and uses a 10% threshold. This threshold establishes the minimum number of samples that would show a given compound for that compound to be included in the analysis. The reason why we don't use a higher threshold is that since we are comparing males and females, we basically assume there's only a 50% chance of a given volatile to be present. 

```{r dataload}
# source("R/master_cleanup.R")
voc_data <- readRDS("cleandata/voc_clean10.RDS")

# this is to use ggplot
long_voc_data <- voc_data %>% 
  gather(., key = "voc", value = "conc", -c(famid, sampid, ssex)) %>% 
  mutate(voc = factor(voc, levels = unique(voc)))

```

## Data exploration
We know we are working with very small numbers and this influences how we will manage the data and what sort of clustering we can do for it. With a quick check, we see that the numbers are very small and that different compounds have very different ranges as well.  
```{r}
long_voc_data %>% 
  ggplot(aes(x = voc, y = conc)) + 
  geom_point() +
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 90))
```

Several of these compounds have a measure of zero, which kind of throws off the scaling and transformations:

```{r}
nsamp <- nrow(voc_data)
# What if we just check the number of zeroes in each?
long_voc_data %>% 
  filter(conc == 0) %>% 
  group_by(voc) %>% 
  tally() %>% 
  ggplot(aes(x = voc, y = n/nsamp)) +
  labs(y = "Proportion of zeroes in data") +
  geom_col() +
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 90))

```

We might want to get a hint of what the data looks like for males and females and how these might differ by family. Which, overall it seems like data between males and females isn't too different, but seems like differences between families might be a thing.  

```{r}

long_voc_data %>% 
  filter(conc > 0) %>% 
  mutate(famid = as.numeric(famid)) %>% 
  ggplot(., aes(x = voc, y = conc, color = famid)) +
  geom_point(alpha = 0.4) +
  scale_color_viridis_c() +
  facet_wrap(~ ssex) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90))

```


```{r facetPlot, fig.height=12}
long_voc_data %>% 
  filter(conc > 0) %>% 
  ggplot(aes(x = voc, y = conc, color = ssex)) +
  geom_point(alpha = 0.5) +
  facet_wrap(~famid, ncol = 6) +
  theme(axis.text.x = element_blank()) +
  scale_color_viridis_d(begin = 0.2, end = 0.8)
```


## Data transformation

With these figures it is very clear that the compounds are at different scales, so we might want to log transform them and check the result, to compare with the first figure. I have chosen not to include the zeroes here since log10(0) = -inf. This actually makes it easy to see that there are some outliers that should probably just be considered a zero. It is pretty clear that most of the compounds we are interested in are in a range.


```{r}
long_voc_data %>% 
  filter(conc > 0) %>%
  ggplot(aes(x = voc, y = conc)) + 
  geom_boxplot() +
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 90)) +
  scale_y_log10()
```



With the information, we can clean the data again and remove these outliers.
```{r}
# Making these outliers be zero
voc_data[voc_data < 10e-15] <- 0

long_voc_data <- voc_data %>% 
  gather(., key = "voc", value = "conc", -c(famid, sampid, ssex)) %>% 
  mutate(voc = factor(voc, levels = unique(voc)))

long_voc_data %>% 
  filter(conc > 0) %>% 
  ggplot(aes(x = voc, y = conc, color = famid, shape = ssex)) + 
  geom_point() +
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 90)) +
  scale_y_log10() +
  scale_color_viridis_c()

```


```{r fig.height=12}
long_voc_data %>% 
  filter(conc > 0) %>% 
  ggplot(aes(x = voc, y = conc, color = ssex)) +
  geom_point(alpha = 0.5) +
  scale_y_log10() +
  facet_wrap(~famid, ncol = 6) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  scale_color_viridis_d(begin = 0.2, end = 0.8)
```
Ok, this is good! and now we have a better idea of the data and how we can work with it for any ordination type of analysis.

# Data transformation
I am thinking that we can log transform the data, and add a really small value, probably set to the detection threshold of the instrument. Once it is in a log scale we can shift the values so that they are not negative but are on the positive side of the spectrum. This is not taking the absolute value but shifting with a sum so that the biggest values correspond to the largest concentrations of the compounds and smaller values correspond to smaller concentrations. If we were to take the absolute value this concept would be inverse and less intuitive. The following histograms are examples of these transformations using the data for compound **m87.04**

```{r}
long_voc_data %>% 
  filter(voc == "m87.04") -> m87.04

# Using this as an example https://www.ionicon.com/information/documentation/frequently-asked-questions#f23
# The threshold for detection is 1 part-per-trillion, so 1e-12

det_thresh <- 1e-12

# Raw distribution
m87.04 %>% 
  ggplot() +
  geom_histogram(aes(x = conc)) + 
  labs(title = "Raw distribution") -> raw

# log distribution, there are 3 zeroes that get removed
m87.04 %>% 
  mutate(conc = log10(conc)) %>% 
  ggplot() +
  geom_histogram(aes(x = conc)) + 
  lims(x = c(-12, 0)) +
  labs(title = "Log transformed - zero removed") -> logh

# if we add the minimum value so we don't loose the zeroes
head(sort(m87.04$conc))
m87.04 %>% 
  mutate(conc = log10(conc + det_thresh)) %>% 
  ggplot() +
  geom_histogram(aes(x = conc)) +
  lims(x = c(-12, 0)) +
  labs(title = "Log - zero set to detection threshold") -> logz

# if to the one we added the minimum we shift it to all values are positive
m87.04 %>% 
  mutate(conc = log10(conc + det_thresh) - log10(det_thresh)) %>%  
  ggplot() +
  geom_histogram(aes(x = conc)) +
  lims(x = c(0, 12)) +
  labs(title = "Log shifted - by detection threshold") -> logzshift

# Take absolute value is like mirror, so all are positives
m87.04 %>% 
  mutate(conc = abs(log10(conc + det_thresh))) %>%  
  ggplot() +
  geom_histogram(aes(x = conc)) +
  lims(x = c(0, 12)) +
  labs(title = "Absolute value log transform") -> logzabs


ggarrange(raw, logh, logz, logzabs, logzshift, ncol = 2, nrow = 3)

```

```{r}
voc_log_data <- voc_data %>% 
  mutate_at(vars(starts_with("m")), list(~ log10(. + det_thresh) - log10(det_thresh)))
```

This is how the transformed data looks now. Zeroes really screw everything up. I'm wondering if we need to think of using rank-based estimators for the correlations, this way the zeros wouldn't affect it so much. We might look into Spearman correlation or Kendall's tau

```{r fig.height=12, eval = FALSE}

voc_log_data %>%
  gather(., key = "voc", value = "conc", -c(famid, sampid, ssex)) %>% 
  mutate(voc = factor(voc, levels = unique(voc))) %>% 
  ggplot(aes(x = voc, y = conc, color = ssex)) +
  geom_point(alpha = 0.5) +
  facet_wrap(~famid, ncol = 6) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  scale_color_viridis_d(begin = 0.2, end = 0.8)

```

```{r}

voc_log_data %>%
  gather(., key = "voc", value = "conc", -c(famid, sampid, ssex)) %>% 
  mutate(voc = factor(voc, levels = unique(voc))) %>% 
  group_by(voc) %>% 
  mutate(median = median(conc),
         potentials = ifelse(median > 4.5, "high", "low"),
         colorpot = ifelse(potentials == "high", "red", "darkgrey")) -> long_logvoc
```

```{r fig.width=12}

long_logvoc %>% 
  select(voc, colorpot) %>% 
  distinct() -> colorstext

long_logvoc%>% 
  #filter(conc > 0) %>% 
  ggplot(aes(x = voc, y = conc, color = potentials)) + 
  geom_boxplot(notch = TRUE) +
  #geom_point() +
  theme_bw() + 
  labs(x = "VOC ID", y = "Log transformed concentration") +
  scale_color_manual(values = c("red", "darkgrey")) +
  theme(axis.text.x = element_text(angle = 90, color = colorstext$colorpot))

```

```{r fig.width=12, eval = FALSE}

long_logvoc%>% 
  filter(ssex == "m") %>% 
  ggplot(aes(x = voc, y = conc, color = potentials)) + 
  geom_boxplot(notch = TRUE) +
  #geom_point() +
  theme_bw() + 
  labs(x = "VOC ID", y = "Log transformed concentration") +
  scale_color_manual(values = c("red", "darkgrey")) +
  theme(axis.text.x = element_text(angle = 90, color = colorstext$colorpot)) -> malesbox


long_logvoc%>% 
  filter(ssex == "f") %>% 
  ggplot(aes(x = voc, y = conc, color = potentials)) + 
  geom_boxplot(notch = TRUE) +
  #geom_point() +
  theme_bw() + 
  labs(x = "VOC ID", y = "Log transformed concentration") +
  scale_color_manual(values = c("red", "darkgrey")) +
  theme(axis.text.x = element_text(angle = 90, color = colorstext$colorpot)) -> fembox

ggarrange(malesbox, fembox, nrow = 2)

```



## Ordination
We will start with a PCA, since the goal of that is to reduce the number of dimensions and see what compounds might be acting in a similar way. The hulls show something we were able to see before, and it's that the males and females overlap on their volatile profiles.


```{r fig.height=7, fig.width=12}

log_pca <- rda(voc_log_data[,4:78])
# Figure for log transformed data
biplot(log_pca, display = c("sites", 
                   "species"),
       type = c("text",
                "points"))
ssex.colors <- levels(factor(voc_data$ssex))
ordihull(log_pca, group = factor(voc_log_data$ssex),
         col = c("blue","black"))
legend("topright", 
       col = c("blue", "black"),
       lty = 1,
       legend = ssex.colors)



```


We can try running a detrended correspondence analysis, but it shows pretty much a similar trend on how the volatiles show up together. It seems to have some influence with their mass, which is kind of intuitive.

```{r fig.height=7, fig.width=12}
dca_voc <- decorana(voc_log_data[,4:78])
plot(dca_voc, display = "species")
```


## NMDS
We can try an NMDS following the process Leslie had done in the past, which still doesn't show convergence. However, we can see that again, that the sexes very much overlap. If we do this by family they overlap as well, it seems like the zeroes really drive this dynamic. Perhaps we will have more luck with the correlations.

```{r}
voc_nmds <- metaMDS(voc_log_data[,4:78])
```

```{r}
scores <- as.data.frame(scores(voc_nmds)) %>% 
  mutate(samplenum = rownames(.),
         family = factor(voc_log_data$famid),
         sex = factor(voc_log_data$ssex))


vol.scores <- voc_nmds$species %>% 
  as.data.frame() %>% 
  mutate(vol.ident = rownames(.))

scores %>% 
  mutate(family = as.numeric(family)) %>% 
  ggplot() +
  theme_bw() + 
  geom_point(aes(x = NMDS1, y = NMDS2, color = family)) +
  #scale_color_viridis_d() +
  scale_color_viridis_c() +
  coord_equal() -> NMDSplot
```


```{r}

scores %>% 
  group_by(sex) %>%
  nest() %>% 
  mutate(
    hull = map(data, ~ with(., chull(NMDS1, NMDS2))),
    out = map2(data, hull, ~ .x[.y,,drop=FALSE])
  ) %>% 
  select(-data) %>% 
  unnest() -> hullData


ggplot() +
  theme_bw() +
  #geom_text(data = spp_scores, aes(x = MDS1, y = MDS2, label = species)) +
  #geom_text(data = scores, aes(x = NMDS1, y = NMDS2, label = site)) + 
  geom_polygon(data = hullData, aes(x = NMDS1, y = NMDS2, fill = sex, group = sex), alpha = 0.2) +
  geom_point(data = scores, aes(x = NMDS1, y = NMDS2, color = sex)) +
  coord_equal() +
  scale_fill_viridis_d() +
  scale_color_viridis_d() -> HULLSplot
```

```{r fig.width=12}

ggarrange(NMDSplot, HULLSplot, ncol = 2)
```

## Correlations


```{r}
# Run different correlations

pears_raw <- cor(voc_data[,4:78])
spear_raw <- cor(voc_data[,4:78], method = "spearman")

pears_log <- cor(voc_log_data[,4:78])
spear_log <- cor(voc_log_data[,4:78], method = "spearman")

all_cors <- list(pears_raw = pears_raw, spear_raw = spear_raw, 
                 pears_log = pears_log, spear_log = spear_log)

```

These correlation matrices are using all of the data, not separated by sexes. We can see that using the rank-based correlation, the values are not affected by the transformation. These correlation matrices are clustered by the correlation coefficients. Based on this, I would rather use a Spearman correlation on the raw data to determine the clustering groups. Based on those clustering groups we can combine them and create a new data frame with the raw data that we can later transform using the same log-shift tranformation.

```{r fig.width=12, fig.height=12}
par(mfrow = c(2,2))
for(i in 1:4){
  title <- names(all_cors)[i]
  
  corrplot(all_cors[[i]], main = title, method = "circle", type = "upper", tl.col = "black", tl.srt = 45, tl.cex = .3, order = "hclust", mar=c(0,0,2,0))
  
  #corrplot(all_cors[[i]], main = title, method = "circle", tl.col = "black", tl.srt = 45, tl.cex = .3, order = "hclust", addrect = 10, mar=c(0,0,2,0))
  
}

```

The following comparison is for clusters between males and females.




Enough of visualizing things. So now let's get some clustering going so we can determine what groups can go together. A question with this is the effect of a transformation on the data and the clustering. And with that, also considering whether we want to take a weighted average of the raw data or the transformed data for each cluster. I would suggest taking the weighted average of the raw data, and with this is probably following the cluster analysis on raw data. The reasoning behind this is that if we take a weighted average we would be going around the issue of having zeroes. They would just get mixed into the averaging process. On the other hand, if some clusters have only 2 or 3 compounds, a zero would have a big effect on the output, but then again, that's why we would be doing weighted averages.

After giving it a little more thought, maybe we want to consider the transformed data instead. If you focus on the cluster from the visualization, it seems like the big cluster from the raw data might just be those compounds that have really small concentrations. So then, these clusters are really just based on the concentrations, so obviously the ones that have super low concentrations might group together. By transforming the data is like we have all the compounds on a similar scale and we can actually compare them to each other and have correlations that make sense on a unified scale.

```{r}
voc_dist <- dist(voc_ordination_data[,4:78], method = "euclidean")
clust_fit <- hclust(voc_dist, method = "ward")
plot(clust_fit)

clust_groups <- cutree(clust_fit, k=2)
rect.hclust(clust_fit, k = 2, border = "red")


voc_ordination_data$cluster <- clust_groups

# table(voc_ordination_data$ssex, voc_ordination_data$cluster)
```



It seems like that is clustering the samples, not the volatiles. So maybe the focus is with correlation matrix and then calculate the distance


```{r}
# For the rawdata
# all_corr <- cor(voc_data[,4:78])

# Or the transformed data
all_corr <- cor(voc_ordination_data[,4:78])

all_dis <- dist(all_corr)
all_clust <- hclust(all_dis)
plot(all_clust)
rect.hclust(all_clust, k = 10)


voc_groups <- cbind(cutree(all_clust, k = 10), rownames(all_corr))

```


Now, I need to use the clusters given in the dendrogram to group the volatiles and calculate weighted averages for each sample.







